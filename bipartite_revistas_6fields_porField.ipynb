{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_F1COM = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F1COM.graphml\")\n",
    "G_F2PSY = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F2PSY.graphml\")\n",
    "G_F3PSC = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F3PSC.graphml\")\n",
    "G_F4SOC = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F4SOC.graphml\")\n",
    "G_F5ECO = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F5ECO.graphml\")\n",
    "G_F6MAN = nx.read_graphml(\"data_EBs_SNA2/loadGraphsFields/complete_bipartite_graph_6fields_F6MAN.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': '10796', 'bipartite': 0, 'Name': 'Robert Hornik\\xa0', 'AffiliationName': 'University of Pennsylvania', 'GenderMC': 1.0, 'GenderAPI': 1.0, 'Country': 'USA', 'GeoAreaMC': 1.0, 'Grado con pesos': 2.0, 'Component ID': 0, 'Eccentricity': 6.0, 'Betweenness Centrality': 96145.51981467682, 'Grado': 2, 'Clustering Coefficient': 0.0, 'Number of triangles': 0, 'Closeness Centrality': 0.2556773066539622, 'Harmonic Closeness Centrality': 0.292877846790891, 'size': 10.0, 'r': 192, 'g': 192, 'b': 192, 'x': -920.22455, 'y': 53.479908}\n",
      "{'label': 'J002', 'bipartite': 1, 'JName': 'Information Communication & Society', 'Field': 'F1C', 'Quartile': 'Q1', 'NumMembersEB': 40, 'IF': 4559, 'Cross-listed': True, 'Cross-fields': 'F1C; F4SOC', 'Grado con pesos': 40.0, 'Component ID': 0, 'Eccentricity': 5.0, 'Betweenness Centrality': 70136.57902262667, 'Grado': 40, 'Clustering Coefficient': 0.0, 'Number of triangles': 0, 'Closeness Centrality': 0.2571884984025559, 'Harmonic Closeness Centrality': 0.2878467908902622, 'size': 10.0, 'r': 192, 'g': 192, 'b': 192, 'x': -174.63194, 'y': -82.58555}\n",
      "{'label': '14420', 'bipartite': 0, 'Name': 'Paul Skilton', 'AffiliationName': 'Washington State University', 'GenderMC': nan, 'GenderAPI': 1.0, 'Country': 'USA', 'GeoAreaMC': nan, 'Grado con pesos': 2.0, 'Eccentricity': 8.0, 'Closeness Centrality': 0.22950028164480565, 'Betweenness Centrality': 185802.00194230725, 'Grado': 2, 'Clustering Coefficient': 0.0, 'Number of triangles': 0, 'Harmonic Closeness Centrality': 0.2521818439858408, 'Component ID': 0, 'size': 10.0, 'r': 192, 'g': 192, 'b': 192, 'x': -575.92065, 'y': 44.196514}\n",
      "{'label': 'J230', 'bipartite': 1, 'JName': 'Management Science', 'Field': 'F6Man', 'Quartile': 'Q1', 'NumMembersEB': 419, 'IF': 3931, 'Cross-listed': False, 'Cross-fields': 'N', 'Grado con pesos': 419.0, 'Eccentricity': 7.0, 'Closeness Centrality': 0.24360452701259877, 'Betweenness Centrality': 3228636.1365405647, 'Grado': 419, 'Clustering Coefficient': 0.0, 'Number of triangles': 0, 'Harmonic Closeness Centrality': 0.30534587257062934, 'Component ID': 0, 'size': 10.0, 'r': 192, 'g': 192, 'b': 192, 'x': 34.538097, 'y': 385.27484}\n"
     ]
    }
   ],
   "source": [
    "#pruebas de carga\n",
    "print(G_F1COM.nodes['10796'])\n",
    "print(G_F1COM.nodes['J002'])\n",
    "print(G_F6MAN.nodes['14420'])\n",
    "print(G_F6MAN.nodes['J230'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: 1COM\n",
      "Nodos: 1611  Aristas: 1836\n",
      "Conexo: True\n",
      "# Connected Components: 1\n",
      "Es bipartito: True\n",
      "Densidad top: 0.04630517023959647\n",
      "Densidad bottom: 0.04630517023959647\n",
      "Avg. Clustering: 0.8128641216954529\n",
      "\n",
      "Field: 2PSY\n",
      "Nodos: 958  Aristas: 957\n",
      "Conexo: False\n",
      "# Connected Components: 11\n",
      "Es bipartito: True\n",
      "Densidad top: 0.051012793176972285\n",
      "Densidad bottom: 0.051012793176972285\n",
      "Avg. Clustering: 0.9519486909864538\n",
      "\n",
      "Field: F3PSC\n",
      "Nodos: 1694  Aristas: 1762\n",
      "Conexo: False\n",
      "# Connected Components: 7\n",
      "Es bipartito: True\n",
      "Densidad top: 0.024269972451790633\n",
      "Densidad bottom: 0.024269972451790633\n",
      "Avg. Clustering: 0.8874508906500208\n",
      "\n",
      "Field: F4SOC\n",
      "Nodos: 1495  Aristas: 1540\n",
      "Conexo: False\n",
      "# Connected Components: 10\n",
      "Es bipartito: True\n",
      "Densidad top: 0.0293199299367908\n",
      "Densidad bottom: 0.0293199299367908\n",
      "Avg. Clustering: 0.9053839337617052\n",
      "\n",
      "Field: F5ECO\n",
      "Nodos: 3997  Aristas: 4267\n",
      "Conexo: False\n",
      "# Connected Components: 13\n",
      "Es bipartito: True\n",
      "Densidad top: 0.011057211416369958\n",
      "Densidad bottom: 0.011057211416369958\n",
      "Avg. Clustering: 0.8624400354182673\n",
      "\n",
      "Field: F6MAN\n",
      "Nodos: 5807  Aristas: 6730\n",
      "Conexo: False\n",
      "# Connected Components: 4\n",
      "Es bipartito: True\n",
      "Densidad top: 0.02053394355453852\n",
      "Densidad bottom: 0.02053394355453852\n",
      "Avg. Clustering: 0.8041917488803255\n"
     ]
    }
   ],
   "source": [
    "#obtener nodos de las dos particiones (RB_top y RB_Bottom)\n",
    "RB_topG_F1COM = {n for n, d in G_F1COM.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F1COM = set(G_F1COM) - RB_topG_F1COM\n",
    "\n",
    "#métricas del grafo bipartito\n",
    "print(\"Field: 1COM\")\n",
    "print(\"Nodos:\",G_F1COM.number_of_nodes(),\" Aristas:\", G_F1COM.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F1COM))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F1COM))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F1COM))\n",
    "print(\"Densidad top:\",bipartite.density(G_F1COM, RB_topG_F1COM))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F1COM, RB_bottomG_F1COM))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F1COM))\n",
    "\n",
    "#repetir para el resto de fields\n",
    "RB_topG_F2PSY = {n for n, d in G_F2PSY.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F2PSY = set(G_F2PSY) - RB_topG_F2PSY\n",
    "\n",
    "print(\"\\nField: 2PSY\")\n",
    "print(\"Nodos:\",G_F2PSY.number_of_nodes(),\" Aristas:\", G_F2PSY.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F2PSY))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F2PSY))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F2PSY))\n",
    "print(\"Densidad top:\",bipartite.density(G_F2PSY, RB_topG_F2PSY))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F2PSY, RB_bottomG_F2PSY))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F2PSY))\n",
    "\n",
    "#F3PSC\n",
    "RB_topG_F3PSC = {n for n, d in G_F3PSC.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F3PSC = set(G_F3PSC) - RB_topG_F3PSC\n",
    "\n",
    "print(\"\\nField: F3PSC\")\n",
    "print(\"Nodos:\",G_F3PSC.number_of_nodes(),\" Aristas:\", G_F3PSC.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F3PSC))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F3PSC))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F3PSC))\n",
    "print(\"Densidad top:\",bipartite.density(G_F3PSC, RB_topG_F3PSC))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F3PSC, RB_bottomG_F3PSC))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F3PSC))\n",
    "\n",
    "#F4SOC\n",
    "RB_topG_F4SOC = {n for n, d in G_F4SOC.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F4SOC = set(G_F4SOC) - RB_topG_F4SOC\n",
    "\n",
    "print(\"\\nField: F4SOC\")\n",
    "print(\"Nodos:\",G_F4SOC.number_of_nodes(),\" Aristas:\", G_F4SOC.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F4SOC))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F4SOC))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F4SOC))\n",
    "print(\"Densidad top:\",bipartite.density(G_F4SOC, RB_topG_F4SOC))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F4SOC, RB_bottomG_F4SOC))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F4SOC))\n",
    "\n",
    "#F5ECO\n",
    "RB_topG_F5ECO = {n for n, d in G_F5ECO.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F5ECO = set(G_F5ECO) - RB_topG_F5ECO\n",
    "\n",
    "print(\"\\nField: F5ECO\")\n",
    "print(\"Nodos:\",G_F5ECO.number_of_nodes(),\" Aristas:\", G_F5ECO.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F5ECO))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F5ECO))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F5ECO))\n",
    "print(\"Densidad top:\",bipartite.density(G_F5ECO, RB_topG_F5ECO))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F5ECO, RB_bottomG_F5ECO))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F5ECO))\n",
    "\n",
    "#F6MAN\n",
    "RB_topG_F6MAN = {n for n, d in G_F6MAN.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F6MAN = set(G_F6MAN) - RB_topG_F6MAN\n",
    "\n",
    "print(\"\\nField: F6MAN\")\n",
    "print(\"Nodos:\",G_F6MAN.number_of_nodes(),\" Aristas:\", G_F6MAN.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F6MAN))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F6MAN))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F6MAN))\n",
    "print(\"Densidad top:\",bipartite.density(G_F6MAN, RB_topG_F6MAN))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F6MAN, RB_bottomG_F6MAN))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F6MAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "True\n",
      "1\n",
      "True\n",
      "1\n",
      "True\n",
      "1\n",
      "True\n",
      "1\n",
      "True\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#Generar el subgrafos con solo la componente principal\n",
    "#COMENTAR  ESTAS LINEAS PARA TRABAJAR CON GRAFO COMPLETO o no ejecutar esta celda\n",
    "#https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.components.connected_components.html#networkx.algorithms.components.connected_components\n",
    "#F1COM\n",
    "largest_cc = max(nx.connected_components(G_F1COM), key=len)\n",
    "G2_F1COM = G_F1COM.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F1COM))\n",
    "print(nx.number_connected_components(G2_F1COM))\n",
    "G_F1COM = G2_F1COM #machacar el oríginal para hacer el resto de cálculos que siguen con G2\n",
    "\n",
    "#F2PSY\n",
    "largest_cc = max(nx.connected_components(G_F2PSY), key=len)\n",
    "G2_F2PSY = G_F2PSY.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F2PSY))\n",
    "print(nx.number_connected_components(G2_F2PSY))\n",
    "G_F2PSY = G2_F2PSY #machacar el oríginal para hacer el resto de cálculos que siguen con G2\n",
    "\n",
    "#F3PSC\n",
    "largest_cc = max(nx.connected_components(G_F3PSC), key=len)\n",
    "G2_F3PSC = G_F3PSC.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F3PSC))\n",
    "print(nx.number_connected_components(G2_F3PSC))\n",
    "G_F3PSC = G2_F3PSC #machacar el oríginal para hacer el resto de cálculos que siguen con G2\n",
    "\n",
    "#F4SOC\n",
    "largest_cc = max(nx.connected_components(G_F4SOC), key=len)\n",
    "G2_F4SOC = G_F4SOC.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F4SOC))\n",
    "print(nx.number_connected_components(G2_F4SOC))\n",
    "G_F4SOC = G2_F4SOC #machacar el oríginal para hacer el resto de cálculos que siguen con G2\n",
    "\n",
    "#F5ECO\n",
    "largest_cc = max(nx.connected_components(G_F5ECO), key=len)\n",
    "G2_F5ECO = G_F5ECO.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F5ECO))\n",
    "print(nx.number_connected_components(G2_F5ECO))\n",
    "G_F5ECO = G2_F5ECO #machacar el oríginal para hacer el resto de cálculos que siguen con G2\n",
    "\n",
    "#F6MAN\n",
    "largest_cc = max(nx.connected_components(G_F6MAN), key=len)\n",
    "G2_F6MAN = G_F6MAN.subgraph(largest_cc).copy()\n",
    "print(nx.is_connected(G2_F6MAN))\n",
    "print(nx.number_connected_components(G2_F6MAN))\n",
    "G_F6MAN = G2_F6MAN #machacar el oríginal para hacer el resto de cálculos que siguen con G2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Field: 1COM\n",
      "Nodos: 1611  Aristas: 1836\n",
      "Conexo: True\n",
      "# Connected Components: 1\n",
      "Es bipartito: True\n",
      "Densidad top: 0.04630517023959647\n",
      "Densidad bottom: 0.04630517023959647\n",
      "Avg. Clustering: 0.8128641216954529\n",
      "\n",
      "Field: 2PSY\n",
      "Nodos: 958  Aristas: 957\n",
      "Conexo: False\n",
      "# Connected Components: 11\n",
      "Es bipartito: True\n",
      "Densidad top: 0.051012793176972285\n",
      "Densidad bottom: 0.051012793176972285\n",
      "Avg. Clustering: 0.9519486909864538\n",
      "\n",
      "Field: F3PSC\n",
      "Nodos: 1694  Aristas: 1762\n",
      "Conexo: False\n",
      "# Connected Components: 7\n",
      "Es bipartito: True\n",
      "Densidad top: 0.024269972451790633\n",
      "Densidad bottom: 0.024269972451790633\n",
      "Avg. Clustering: 0.8874508906500208\n",
      "\n",
      "Field: F4SOC\n",
      "Nodos: 1495  Aristas: 1540\n",
      "Conexo: False\n",
      "# Connected Components: 10\n",
      "Es bipartito: True\n",
      "Densidad top: 0.0293199299367908\n",
      "Densidad bottom: 0.0293199299367908\n",
      "Avg. Clustering: 0.9053839337617052\n",
      "\n",
      "Field: F5ECO\n",
      "Nodos: 3997  Aristas: 4267\n",
      "Conexo: False\n",
      "# Connected Components: 13\n",
      "Es bipartito: True\n",
      "Densidad top: 0.011057211416369958\n",
      "Densidad bottom: 0.011057211416369958\n",
      "Avg. Clustering: 0.8624400354182673\n",
      "\n",
      "Field: F6MAN\n",
      "Nodos: 5807  Aristas: 6730\n",
      "Conexo: False\n",
      "# Connected Components: 4\n",
      "Es bipartito: True\n",
      "Densidad top: 0.02053394355453852\n",
      "Densidad bottom: 0.02053394355453852\n",
      "Avg. Clustering: 0.8041917488803255\n"
     ]
    }
   ],
   "source": [
    "#Vuelve a sacar todas las métricas de las 6 subredes para comparar\n",
    "RB_topG_F1COM = {n for n, d in G_F1COM.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F1COM = set(G_F1COM) - RB_topG_F1COM\n",
    "\n",
    "#métricas del grafo bipartito\n",
    "print(\"Field: 1COM\")\n",
    "print(\"Nodos:\",G_F1COM.number_of_nodes(),\" Aristas:\", G_F1COM.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F1COM))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F1COM))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F1COM))\n",
    "print(\"Densidad top:\",bipartite.density(G_F1COM, RB_topG_F1COM))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F1COM, RB_bottomG_F1COM))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F1COM))\n",
    "\n",
    "#repetir para el resto de fields\n",
    "RB_topG_F2PSY = {n for n, d in G_F2PSY.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F2PSY = set(G_F2PSY) - RB_topG_F2PSY\n",
    "\n",
    "print(\"\\nField: 2PSY\")\n",
    "print(\"Nodos:\",G_F2PSY.number_of_nodes(),\" Aristas:\", G_F2PSY.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F2PSY))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F2PSY))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F2PSY))\n",
    "print(\"Densidad top:\",bipartite.density(G_F2PSY, RB_topG_F2PSY))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F2PSY, RB_bottomG_F2PSY))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F2PSY))\n",
    "\n",
    "#F3PSC\n",
    "RB_topG_F3PSC = {n for n, d in G_F3PSC.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F3PSC = set(G_F3PSC) - RB_topG_F3PSC\n",
    "\n",
    "print(\"\\nField: F3PSC\")\n",
    "print(\"Nodos:\",G_F3PSC.number_of_nodes(),\" Aristas:\", G_F3PSC.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F3PSC))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F3PSC))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F3PSC))\n",
    "print(\"Densidad top:\",bipartite.density(G_F3PSC, RB_topG_F3PSC))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F3PSC, RB_bottomG_F3PSC))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F3PSC))\n",
    "\n",
    "#F4SOC\n",
    "RB_topG_F4SOC = {n for n, d in G_F4SOC.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F4SOC = set(G_F4SOC) - RB_topG_F4SOC\n",
    "\n",
    "print(\"\\nField: F4SOC\")\n",
    "print(\"Nodos:\",G_F4SOC.number_of_nodes(),\" Aristas:\", G_F4SOC.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F4SOC))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F4SOC))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F4SOC))\n",
    "print(\"Densidad top:\",bipartite.density(G_F4SOC, RB_topG_F4SOC))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F4SOC, RB_bottomG_F4SOC))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F4SOC))\n",
    "\n",
    "#F5ECO\n",
    "RB_topG_F5ECO = {n for n, d in G_F5ECO.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F5ECO = set(G_F5ECO) - RB_topG_F5ECO\n",
    "\n",
    "print(\"\\nField: F5ECO\")\n",
    "print(\"Nodos:\",G_F5ECO.number_of_nodes(),\" Aristas:\", G_F5ECO.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F5ECO))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F5ECO))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F5ECO))\n",
    "print(\"Densidad top:\",bipartite.density(G_F5ECO, RB_topG_F5ECO))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F5ECO, RB_bottomG_F5ECO))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F5ECO))\n",
    "\n",
    "#F6MAN\n",
    "RB_topG_F6MAN = {n for n, d in G_F6MAN.nodes(data=True) if d['bipartite']==0}\n",
    "RB_bottomG_F6MAN = set(G_F6MAN) - RB_topG_F6MAN\n",
    "\n",
    "print(\"\\nField: F6MAN\")\n",
    "print(\"Nodos:\",G_F6MAN.number_of_nodes(),\" Aristas:\", G_F6MAN.number_of_edges())\n",
    "print(\"Conexo:\", nx.is_connected(G_F6MAN))\n",
    "print(\"# Connected Components:\",nx.number_connected_components(G_F6MAN))\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G_F6MAN))\n",
    "print(\"Densidad top:\",bipartite.density(G_F6MAN, RB_topG_F6MAN))\n",
    "print(\"Densidad bottom:\",bipartite.density(G_F6MAN, RB_bottomG_F6MAN))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G_F6MAN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcular métricas. elegir un campo ajustando comentarios     F1COM F2PSY F3PSC F4SOC F5ECO F6MAN\n",
    "#field = \"F1COM\"\n",
    "#G2 = G2_F1COM #sustituir por G2 = G_F1COM si no se ejecuta la celda 5 (toda la red). Idem para el reto de fields\n",
    "#RB_top = RB_topG_F1COM\n",
    "\n",
    "field = \"F2PSY\" #Hecho dos veces: solo CC (ejecutar todo) y toda la red (no ejecutar celda 5)\n",
    "G2 = G_F2PSY    #Para PSY mejor con el grafo completo. Subred muy fragmentada\n",
    "RB_top = RB_topG_F2PSY\n",
    "\n",
    "#field = \"F3PSC\"\n",
    "#G2 = G2_F3PSC\n",
    "#RB_top = RB_topG_F3PSC\n",
    "\n",
    "#field = \"F4SOC\"\n",
    "#G2 = G2_F4SOC\n",
    "#RB_top = RB_topG_F4SOC\n",
    "\n",
    "#field = \"F5ECO\"\n",
    "#G2 = G2_F5ECO\n",
    "#RB_top = RB_topG_F5ECO\n",
    "\n",
    "#field = \"F6MAN\"\n",
    "#G2 = G2_F6MAN\n",
    "#RB_top = RB_topG_F6MAN\n",
    "\n",
    "#calcular métricas.\n",
    "dc_top = bipartite.degree_centrality(G2, RB_top)\n",
    "cc_top = bipartite.closeness_centrality(G2, RB_top)\n",
    "bc_top = bipartite.betweenness_centrality(G2, RB_top)\n",
    "clustering_coeff = bipartite.clustering(G2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 7)\n",
      "JName           object\n",
      "Field           object\n",
      "Quartile        object\n",
      "NumMembersEB     int64\n",
      "IF               int64\n",
      "Cross-listed      bool\n",
      "Cross-fields    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#cargar atributos de los nodos de los ficheros. \"Id\" se utiliza como índice\n",
    "#carga el dataset completo aunque luego se usen los members de un solo field!!!\n",
    "personasDf = pd.read_excel(\"data_EBs_SNA2/1EBmembers_v2.2.xlsx\", index_col=0)\n",
    "#print(personasDf.shape)\n",
    "#print(personasDf.dtypes)\n",
    "#print(personasDf.head())\n",
    "#print(personasDf.tail())\n",
    "for indice, fila in personasDf.iterrows():\n",
    "    if(indice in G2.nodes):\n",
    "        G2.nodes[indice][\"Name\"]=fila[\"Name\"]\n",
    "        G2.nodes[indice][\"AffiliationName\"]=fila[\"AffiliationName\"]\n",
    "        G2.nodes[indice][\"GenderMC\"]=fila[\"GenderMC\"]\n",
    "        G2.nodes[indice][\"GenderAPI\"]=fila[\"GenderAPI\"]\n",
    "        G2.nodes[indice][\"Country\"]=fila[\"AffiliationCountry\"]\n",
    "        G2.nodes[indice][\"GeoAreaMC\"]=fila[\"GeoAreaMC\"]\n",
    "        \n",
    "#cargar los nodos de los atributos (revistas) de fichero\n",
    "revistasDf = pd.read_excel(\"data_EBs_SNA2/2Journals_v2.2.xlsx\", index_col=0)\n",
    "print(revistasDf.shape)\n",
    "print(revistasDf.dtypes)\n",
    "#print(revistasDf.head())\n",
    "for indiceR, filaR in revistasDf.iterrows():\n",
    "    if(indiceR in G2.nodes):\n",
    "        G2.nodes[indiceR][\"JName\"]=filaR[\"JName\"]\n",
    "        G2.nodes[indiceR][\"Field\"]=filaR[\"Field\"]\n",
    "        G2.nodes[indiceR][\"Quartile\"]=filaR[\"Quartile\"]\n",
    "        G2.nodes[indiceR][\"NumMembersEB\"]=filaR[\"NumMembersEB\"]\n",
    "        G2.nodes[indiceR][\"IF\"]=filaR[\"IF\"]\n",
    "        G2.nodes[indiceR][\"Cross-listed\"]=filaR[\"Cross-listed\"]\n",
    "        G2.nodes[indiceR][\"Cross-fields\"]=filaR[\"Cross-fields\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append de las métricas a los dataframes iniciales (personasDf, revistasDf)\n",
    "#append degree centrality (dc_top)\n",
    "\n",
    "personasDf.index = personasDf.index.map(str) #recastear index. si no el .join no va bien por ser distintos tipos\n",
    "\n",
    "dcTop_Df = pd.DataFrame.from_dict(dc_top, orient='index', columns=['degreeCentrality'])\n",
    "resultPersonasDf = personasDf.join(dcTop_Df) #importante usar un DF distinto la primera ver por si se quiere ejecutar la celda más de una vez. si no da error al intentar duplicar columnas\n",
    "resultRevistasDf = revistasDf.join(dcTop_Df) #importante usar un DF distinto también\n",
    "\n",
    "#append closeness centrality (cc_top)\n",
    "ccTop_Df = pd.DataFrame.from_dict(cc_top, orient='index', columns=['closenessCentrality'])\n",
    "resultPersonasDf = resultPersonasDf.join(ccTop_Df)\n",
    "resultRevistasDf = resultRevistasDf.join(ccTop_Df)\n",
    "\n",
    "#append betweenness centrality (bc_top)\n",
    "bcTop_Df = pd.DataFrame.from_dict(bc_top, orient='index', columns=['betweennessCentrality'])\n",
    "resultPersonasDf = resultPersonasDf.join(bcTop_Df)\n",
    "resultRevistasDf = resultRevistasDf.join(bcTop_Df)\n",
    "\n",
    "#append clustering coefficient (clustering_coeff)\n",
    "clustering_coeff_Df = pd.DataFrame.from_dict(clustering_coeff, orient='index', columns=['clusteringCoefficient'])\n",
    "resultPersonasDf = resultPersonasDf.join(clustering_coeff_Df)\n",
    "resultRevistasDf = resultRevistasDf.join(clustering_coeff_Df)\n",
    "\n",
    "#guardar Excels con los datasets completos\n",
    "resultPersonasDf.to_excel(\"data_EBs_SNA2/RMetricsMembersDS_\"+field+\".xlsx\")\n",
    "resultRevistasDf.to_excel(\"data_EBs_SNA2/RMetricsJournalsDS_\"+field+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bipartite': 1, 'Name': 'University of California Santa Barbara', 'Scholars': 1}\n",
      "{'bipartite': 1, 'Name': 'University of Pennsylvania', 'Scholars': 4}\n",
      "Es bipartito: True\n",
      "Densidad top: 0.07917647058823529\n",
      "Densidad bottom: 0.07917647058823529\n",
      "Avg. Clustering: 0.5285920088909526\n"
     ]
    }
   ],
   "source": [
    "#crear grafo revistas-afilicaiones (G3). \n",
    "G3=nx.Graph()\n",
    "#inicializar grafo solo con revistas (nodos)\n",
    "for n in G2.nodes:\n",
    "    if G2.nodes[n][\"bipartite\"]: G3.add_node(n, bipartite=0, Name=G2.nodes[n][\"JName\"])\n",
    "\n",
    "#añadir las afiliaciones (nodos)\n",
    "for n in G2.nodes:\n",
    "    if G2.nodes[n][\"bipartite\"]==0:\n",
    "        #print(G2.nodes[n][\"Affiliation\"])\n",
    "        if G2.nodes[n][\"AffiliationName\"] not in G3:\n",
    "            #Affiliation no está en grafo. Añadir\n",
    "            G3.add_node(G2.nodes[n][\"AffiliationName\"], bipartite=1, Name=G2.nodes[n][\"AffiliationName\"], Scholars=1)\n",
    "        else:\n",
    "            G3.nodes[G2.nodes[n][\"AffiliationName\"]][\"Scholars\"] +=1\n",
    "\n",
    "print(G3.nodes['University of California Santa Barbara'])\n",
    "print(G3.nodes['University of Pennsylvania'])            \n",
    "\n",
    "#añadir aristas (con peso)\n",
    "for n in G2.nodes:\n",
    "    if G2.nodes[n][\"bipartite\"]==0: #por cada miembro\n",
    "        #print(\"nodo:\", n, type(n))\n",
    "        for e in G2[n]: #por cada arista (revistas de las que es miembro)\n",
    "            affil = G2.nodes[n][\"AffiliationName\"]\n",
    "            arista = (e, affil)\n",
    "            #print(\"arista:\",e, affil,arista in G3.edges)\n",
    "            if arista in G3.edges:\n",
    "                #ya hay otro miembro anterior de esa revista-institución\n",
    "                G3.edges[e, affil][\"weight\"] +=1\n",
    "            else:\n",
    "                #no hay ninguno anterior\n",
    "                G3.add_edge(e, affil, weight=1)              \n",
    "\n",
    "#métricas del grafo bipartito\n",
    "print(\"Es bipartito:\", bipartite.is_bipartite(G3))\n",
    "RB_topG3 = {n for n, d in G3.nodes(data=True) if d[\"bipartite\"]==0}\n",
    "RB_bottomG3 = set(G3) - RB_topG3\n",
    "print(\"Densidad top:\",bipartite.density(G3, RB_topG3))\n",
    "print(\"Densidad bottom:\",bipartite.density(G3, RB_bottomG3))\n",
    "print(\"Avg. Clustering:\",bipartite.average_clustering(G3))\n",
    "\n",
    "#guardar grafo\n",
    "nx.write_gexf(G3, \"data_EBs_SNA2/grafo_bipartito_revistas_afiliaciones_\"+field+\".gexf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#métricas de red instituciones-revistas\n",
    "#degree_centrality\n",
    "dc_topG3 = bipartite.degree_centrality(G3, RB_topG3)\n",
    "\n",
    "#closeness_centrality. tarda un poco\n",
    "cc_topG3 = bipartite.closeness_centrality(G3, RB_topG3)\n",
    "\n",
    "#betweenness_centrality. tarda un poco\n",
    "bc_topG3 = bipartite.betweenness_centrality(G3, RB_topG3)\n",
    "\n",
    "#clustering (según la documentacion puede ser para todo el grafo)\n",
    "clustering_coeffG3 = bipartite.clustering(G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#guardar dataset instituciones\n",
    "#primero crear DF solo afiliaciones. Están en RB_bottomG3 (type=set)\n",
    "institucionesDf = pd.DataFrame(index=list(RB_bottomG3))\n",
    "\n",
    "#append degree centrality (dc_topG3)\n",
    "dcTopG3_Df = pd.DataFrame.from_dict(dc_topG3, orient='index', columns=['degreeCentrality'])\n",
    "resultInstitucionesDf = institucionesDf.join(dcTopG3_Df) #importante usar un DF distinto la primera ver por si se quiere ejecutar la celda más de una vez. si no da error al intentar duplicar columnas\n",
    "\n",
    "#append closeness centrality (cc_topG3)\n",
    "ccTopG3_Df = pd.DataFrame.from_dict(cc_topG3, orient='index', columns=['closenessCentrality'])\n",
    "resultInstitucionesDf = resultInstitucionesDf.join(ccTopG3_Df)\n",
    "\n",
    "#append betweenness centrality (bc_topG3)\n",
    "bcTopG3_Df = pd.DataFrame.from_dict(bc_topG3, orient='index', columns=['betweennessCentrality'])\n",
    "resultInstitucionesDf = resultInstitucionesDf.join(bcTopG3_Df)\n",
    "\n",
    "#append clustering coefficient (clustering_coeffG3)\n",
    "clustering_coeffG3_Df = pd.DataFrame.from_dict(clustering_coeffG3, orient='index', columns=['clusteringCoefficient'])\n",
    "resultInstitucionesDf = resultInstitucionesDf.join(clustering_coeffG3_Df)\n",
    "\n",
    "#append num de scholars de cada institución\n",
    "#primero sacarlo del grafo y convertirlo en diccionario\n",
    "num_scholars_dict = dict()\n",
    "for n in G3.nodes:\n",
    "    if G3.nodes[n][\"bipartite\"]==1: #por cada institución\n",
    "        num_scholars_dict[G3.nodes[n][\"Name\"]] = G3.nodes[n][\"Scholars\"]\n",
    "#añadirlo al dataset\n",
    "num_scholarsG3_Df = pd.DataFrame.from_dict(num_scholars_dict, orient='index', columns=['numScholars'])\n",
    "resultInstitucionesDf = resultInstitucionesDf.join(num_scholarsG3_Df)\n",
    "\n",
    "#guardar Excel con dataset completo\n",
    "resultInstitucionesDf.to_excel(\"data_EBs_SNA2/RinstitucionesDS_\"+field+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Densidad inicial de la proyeccion: 0.14805771365149833\n",
      "Densidad weighted graph (debería ser la misma): 0.14805771365149833\n",
      "Densidad tras eliminar edges que cumplen criterio: 0.00026637069922308545\n"
     ]
    }
   ],
   "source": [
    "#sacar proyección solo instituciones\n",
    "GInstituciones = bipartite.projected_graph(G3, RB_bottomG3)\n",
    "nx.write_gexf(GInstituciones, \"data_EBs_SNA2/grafo_proy_instituciones_\"+field+\".gexf\")\n",
    "print(\"Densidad inicial de la proyeccion:\", nx.density(GInstituciones))\n",
    "\n",
    "#Sacar las proyecciones que cumplan determinados criterios.\n",
    "#primero sacar los weighted\n",
    "GInstitucionesW = bipartite.weighted_projected_graph(G3, RB_bottomG3)\n",
    "nx.write_gexf(GInstitucionesW, \"data_EBs_SNA2/grafo_proy_institucionesWeightedCompleto_\"+field+\".gexf\")\n",
    "print(\"Densidad weighted graph (debería ser la misma):\", nx.density(GInstitucionesW))\n",
    "\n",
    "#quitar los edges con weight<x \n",
    "listaEdgesInstitucionesBorrar = []\n",
    "for (u,v,d) in GInstitucionesW.edges(data='weight'):\n",
    "    if d<4: listaEdgesInstitucionesBorrar.append((u,v))\n",
    "GInstitucionesW.remove_edges_from(listaEdgesInstitucionesBorrar)\n",
    "#guardar grafo\n",
    "nx.write_gexf(GInstitucionesW, \"data_EBs_SNA2/grafo_proy_InstitucionesWeightedMayorIgual4_\"+field+\".gexf\")\n",
    "print(\"Densidad tras eliminar edges que cumplen criterio:\", nx.density(GInstitucionesW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
